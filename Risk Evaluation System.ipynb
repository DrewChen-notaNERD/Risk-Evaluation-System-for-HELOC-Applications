{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m in \u001b[0;35m<cell line: 2>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m\u001b[0;31m:\u001b[0m No module named 'pandas'\n"
     ]
    }
   ],
   "source": [
    "# packages that may be needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"./heloc_dataset_v1.csv\")\n",
    "seed = 668\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ExternalRiskEstimate == -9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some statistics\n",
    "n_rows = len(df)\n",
    "n_cols = df.shape[1]\n",
    "col_names = list(df.columns)\n",
    "row_indexes = list(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# seems like no null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# is there any prob about unit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().any(axis = 0).sum() , df.isnull().any(axis = 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_numeric = list(df.dtypes[df.dtypes==int].index)\n",
    "cols_string = list(df.dtypes[df.dtypes!=int].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are many similar, negative outliers for different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ExternalRiskEstimate'].hist(figsize=(15,5), bins=50); # reflect about the syntax of this command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that values mostly vary between 30-90, and there is some accumulation of negative values. \n",
    "\n",
    "According to the documentation of the data (available in the Excel file `heloc_data_dictionary-2.xlsx`), the column ExternalRiskEstimate refers to the \"Consolidated version of risk markers.\" \n",
    "\n",
    "The file also indicates that 3 special values are used to encode missing values: -7,-8, and -9. \n",
    "\n",
    "Let's look at some of the rows that contain missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_ExternalRiskEstimate = df[df.ExternalRiskEstimate == -9]\n",
    "n_rows_with_missing_ExternalRiskEstimate = len(df_missing_ExternalRiskEstimate)\n",
    "n_rows_with_all_numeric_missing = len(df.loc[df.iloc[:,1:].sum(axis = 1) == (n_cols-1)*(-9)])\n",
    "df_without_missing_rows = df.iloc[((df.iloc[:,1:] == -9).sum(axis = 1) != len(df.columns)-1).values,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_rows_with_missing_ExternalRiskEstimate, n_rows_with_all_numeric_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So 588/599 of the observations whose labels are missing are with all numeric columns missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_missing_rows.boxplot(figsize = (15,5))\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_feature_value_per_group = df_without_missing_rows.groupby([\"RiskPerformance\"]).mean().T\n",
    "df_avg_feature_value_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_missing_rows = df_without_missing_rows[col_names[1:]+[\"RiskPerformance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_missing_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_missing_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate features and labels\n",
    "df = df_without_missing_rows\n",
    "X = df.iloc[:,:23]\n",
    "Y = df.iloc[:,-1]\n",
    "Y = (Y == \"Bad\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df == -9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ExternalRiskEstimate == -9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.ExternalRiskEstimate == -9])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state = 668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train,Y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_train.groupby(\"ExternalRiskEstimate\").mean()[\"RiskPerformance\"]\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_train.groupby(\"ExternalRiskEstimate\").count()[\"RiskPerformance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize = (20,7))\n",
    "means.plot.bar(ax = axes[0])\n",
    "counts.plot.bar(ax = axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[X_train[\"ExternalRiskEstimate\"] != -9]\n",
    "X_test  = X_test[X_test[\"ExternalRiskEstimate\"] != -9]\n",
    "Y_train = Y_train[X_train.index]\n",
    "Y_test  = Y_test[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline - donothing columntransformer + missingindicator + simpleimputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "\n",
    "# feature_expansion = FeatureUnion([(\"do nothing\", ColumnTransformer([(\"Imputer -7 to mean\", SimpleImputer(missing_values = -7, strategy = \"mean\"), [])], remainder = \"passthrough\")),\n",
    "#                     (\"add features for -7\", MissingIndicator(missing_values= -7, features = \"missing-only\")),\n",
    "#                     (\"add features for -8\", MissingIndicator(missing_values = -8, features = \"missing-only\")),])\n",
    "\n",
    "# pipeline = Pipeline([(\"expand features\", feature_expansion),\n",
    "#                     (\"replace -7 with -8\", SimpleImputer(missing_values = -7, strategy = \"constant\", fill_value = -8)),\n",
    "#                     (\"replace -8 with average\", SimpleImputer(missing_values = -8, strategy = \"mean\"))])\n",
    "# arr_X_train_t = pipeline.fit_transform(X_train)\n",
    "\n",
    "do_nothing_imputer = ColumnTransformer([(\"Imputer -7 to mean\", SimpleImputer(missing_values = -7, strategy = 'mean'), [])],remainder = 'passthrough')\n",
    "\n",
    "feature_expansion = FeatureUnion([(\"do nothing\", do_nothing_imputer),\n",
    "                                  (\"missing_minus_7\", MissingIndicator(missing_values = -7, features = \"missing-only\")),\n",
    "                                  (\"missing_minus_8\", MissingIndicator(missing_values = -8, features = \"missing-only\"))])\n",
    "\n",
    "pipeline = Pipeline([(\"expand features\", feature_expansion),\n",
    "                    (\"replace -7 with -8\", SimpleImputer(missing_values = -7, strategy = \"constant\", fill_value = -8)),\n",
    "                    (\"replace -8 with average\", SimpleImputer(missing_values = -8, strategy = \"mean\"))])\n",
    "arr_X_train_t = pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_7_indicator_transformer = MissingIndicator(missing_values=-7, features='missing-only').fit(X_train)\n",
    "minus_8_indicator_transformer = MissingIndicator(missing_values=-8, features='missing-only').fit(X_train)\n",
    "col_names_minus_7 = X_train.columns.values[minus_7_indicator_transformer.features_].tolist() \n",
    "col_names_minus_7 = list(map(lambda s: str(s)+'=-7', col_names_minus_7))\n",
    "col_names_minus_8 = X_train.columns.values[minus_8_indicator_transformer.features_].tolist()\n",
    "col_names_minus_8 = list(map(lambda s:str(s)+'=-8', col_names_minus_8))\n",
    "columns_all = X_train.columns.values.tolist() + col_names_minus_7 + col_names_minus_8\n",
    "column_names = columns_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train_t = pd.DataFrame(arr_X_train_t,columns= column_names)\n",
    "X_test_t = pd.DataFrame(pipeline.transform(X_test), columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import tree, linear_model, neighbors    \n",
    "cv_results_tree = cross_validate(tree.DecisionTreeClassifier(), X_train_t, Y_train, cv=5, return_estimator=True)\n",
    "cv_results_log_reg = cross_validate(linear_model.LogisticRegression(max_iter=10000), X_train_t, Y_train, cv=5, return_estimator=True)\n",
    "cv_results_knn = cross_validate(neighbors.KNeighborsClassifier(), X_train_t, Y_train, cv=5, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification tree - CV accuracy score %.3f'%cv_results_tree['test_score'].mean()) # this is their average value\n",
    "print('Logistic regresion - CV accuracy score %.3f'%cv_results_log_reg['test_score'].mean()) # this is their average value\n",
    "print('KNN - CV accuracy score %.3f'%cv_results_knn['test_score'].mean()) # this is their average value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'max_depth':[1,2,3,4,5,6,7,8,9,10],  \n",
    "               'criterion':[\"gini\", \"entropy\"],            \n",
    "               'min_samples_split':[2,5,10],              \n",
    "               'min_samples_leaf':[10,20,30]}]\n",
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(clf_tree, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_t,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_ # variable holding the best classifier (fitted on the entire dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best = cross_validate(tree.DecisionTreeClassifier(max_depth=7,min_samples_leaf=20, min_samples_split= 5, criterion= 'entropy'), X_train_t,Y_train, cv=5,return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "lr = LogisticRegression()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats = 3, random_state = 668)\n",
    "search = GridSearchCV(lr,space,scoring = \"accuracy\", n_jobs = -1, cv=cv)\n",
    "search.fit(X_train_t,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best = cross_validate(LogisticRegression(C=0.1, solver = 'newton-cg'), X_train_t,Y_train, cv=5,return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best = cross_validate(LogisticRegression(C=0.1, solver = 'newton-cg'), X_test_t,Y_test, cv=5,return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test accuracy score using best param on whole test set\n",
    "lr = LogisticRegression(C=0.1, solver = 'newton-cg')\n",
    "lr.fit(X_train_t,Y_train)\n",
    "lr.score(X_test_t, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in pipeline\n",
    "do_nothing_imputer = ColumnTransformer([(\"Imputer -7 to mean\", SimpleImputer(missing_values = -7, strategy = 'mean'), [])],remainder = 'passthrough')\n",
    "\n",
    "feature_expansion = FeatureUnion([(\"do nothing\", do_nothing_imputer),\n",
    "                                  (\"missing_minus_7\", MissingIndicator(missing_values = -7, features = \"missing-only\")),\n",
    "                                  (\"missing_minus_8\", MissingIndicator(missing_values = -8, features = \"missing-only\"))])\n",
    "\n",
    "final_model = Pipeline([(\"expand features\", feature_expansion),\n",
    "                        (\"replace -7 with -8\", SimpleImputer(missing_values = -7, strategy = \"constant\", fill_value = -8)),\n",
    "                        (\"replace -8 with average\", SimpleImputer(missing_values = -8, strategy = \"mean\")),\n",
    "                        ('classifier',LogisticRegression(C=0.1, solver = 'newton-cg'))])\n",
    "\n",
    "\n",
    "final_model.fit(X_train,Y_train)\n",
    "final_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Odds ratio\n",
    "# Numerical feature: If you increase the value of feature x\n",
    "# by one unit, the estimated odds change by a factor of \n",
    "\n",
    "res = np.exp(final_model.named_steps['classifier'].coef_)\n",
    "res = pd.DataFrame(res, columns = X_train_t.columns)\n",
    "res = res.transpose()\n",
    "\n",
    "res = res.reset_index(level = 0)\n",
    "res.columns = ['feature', 'Odds_ratios']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(30, 25))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(data = res,x= 'feature', y = 'Odds_ratios',palette = 'magma',order=res.sort_values('Odds_ratios').feature)\n",
    "plt.savefig('Odds_ratios_visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.named_steps['classifier'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(0.362968655)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
